{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423e293e",
   "metadata": {},
   "source": [
    "# Data Scientist - P7 - Laurent Trichet\n",
    "\n",
    "## Implémentez un modèle de scoring\n",
    "\n",
    "## 4 Generate prediction pipeline and deployment model with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b059e56",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e145eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import default libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Garbage Collector (empty dataFrame memory)\n",
    "import gc\n",
    "\n",
    "# Import Imbalanced-learn necessary tools\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "\n",
    "# import for classification GradientBoostingClassifier & SVC\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Import evaluation tool for classification optimisations\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import mlflow, serialization and model server\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# tools for execution time estimates\n",
    "from datetime import datetime\n",
    "\n",
    "# Remove some warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "DIRDATASET = './credithome_datasets/'\n",
    "NUMROWS = 15000       # 1000000 = total dataset\n",
    "# File names with NUMROWS lines, Fill nan with zeros and important features only\n",
    "FILESTD_FNAN0_REDUCED = DIRDATASET+'Credit_Home_Junction_Std_Fnan0_Reduced_'+str(NUMROWS)+'.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00daa1db",
   "metadata": {},
   "source": [
    "### 4.1 Load training and test sets, apply correction of imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61f0c9",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa3f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(FILESTD_FNAN0_REDUCED, encoding='Latin-1', sep='\\t')\n",
    "\n",
    "# Retrieve train and test datasets\n",
    "df_train = df[df['TARGET']!=999]\n",
    "df_test = df[df['TARGET']==999]\n",
    "# Keep valid columns for features and result class in future classifications\n",
    "c_features = [c for c in df.columns if c not in ['index', 'TARGET', 'SK_ID_CURR']]\n",
    "c_class = 'TARGET'\n",
    "\n",
    "del df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295539c9",
   "metadata": {},
   "source": [
    "#### Under sampling for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dced4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 13826, 0.0: 1174})\n"
     ]
    }
   ],
   "source": [
    "counter1 = Counter(df_train[c_class])\n",
    "print(counter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55aa21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 1174, 1.0: 1174})\n"
     ]
    }
   ],
   "source": [
    "undersample = imblearn.under_sampling.RandomUnderSampler(random_state=0)\n",
    "df_X, df_y = undersample.fit_resample(df_train[c_features], df_train[c_class])\n",
    "X = df_X.values\n",
    "y = df_y.values\n",
    "\n",
    "del df_X, df_y\n",
    "gc.collect()\n",
    "\n",
    "counter2 = Counter(y)\n",
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5d9cf",
   "metadata": {},
   "source": [
    "### 4.2 Search for best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd4dcf",
   "metadata": {},
   "source": [
    "#### Pre-training, search best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "iname, itype, iparam = 0, 1, 2\n",
    "models.append(['GradBoostC', ensemble.GradientBoostingClassifier(),\n",
    "               {\n",
    "                'n_estimators': [200],\n",
    "                'max_depth': [3],\n",
    "                'criterion': ['friedman_mse'],\n",
    "                'min_samples_split': [2, 3],\n",
    "                'min_weight_fraction_leaf': [0.0, 0.2, 0.4],\n",
    "                 }\n",
    "               ])\n",
    "for i, model in enumerate(models):\n",
    "    mdl = GridSearchCV(model[itype], model[iparam], cv=5, scoring='roc_auc')\n",
    "    datedeb = datetime.now()\n",
    "    mdl.fit(X, y)\n",
    "    duree = datetime.now() - datedeb\n",
    "    print(f'{model[iname]} \\tduree: {duree.seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86027292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\tbest_score: {mdl.best_score_:4.3} \\tbest_params: {mdl.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117a497",
   "metadata": {},
   "source": [
    "#### Result for 15000 training dataset : best_score: 0.733 \tbest_params: {'criterion': 'friedman_mse', 'max_depth': 3, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200}\n",
    "#### Result for full dataset : best_score: 0.772 \tbest_params: {'criterion': 'friedman_mse', 'max_depth': 3, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = mdl.predict_proba(df_test[c_features])\n",
    "dtf = pd.DataFrame(test_prob)\n",
    "dtf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330f776",
   "metadata": {},
   "source": [
    "### 4.3 Creation of a prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad439f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('classifier',\n",
    "                   ensemble.GradientBoostingClassifier(\n",
    "                                n_estimators=200,\n",
    "                                max_depth=3,\n",
    "                                criterion='friedman_mse',\n",
    "                                min_samples_split = 2,\n",
    "                                min_weight_fraction_leaf = 0.0,\n",
    "                            )\n",
    "                 )\n",
    "                ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ccf04cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier', GradientBoostingClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc78b88c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\trich\\OneDrive\\OpenClassrooms\\Parcours Data Scientist\\P7 Implementez Modele Scoring\\Code\\HomeCredit\\API\\P7_04_Classification_MLFlow_creation.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/trich/OneDrive/OpenClassrooms/Parcours%20Data%20Scientist/P7%20Implementez%20Modele%20Scoring/Code/HomeCredit/API/P7_04_Classification_MLFlow_creation.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m dtf\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/trich/OneDrive/OpenClassrooms/Parcours%20Data%20Scientist/P7%20Implementez%20Modele%20Scoring/Code/HomeCredit/API/P7_04_Classification_MLFlow_creation.ipynb#ch0000018?line=1'>2</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dtf' is not defined"
     ]
    }
   ],
   "source": [
    "del dtf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3775e",
   "metadata": {},
   "source": [
    "### 4.4 Deployment API of sklearn model with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fbf708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float64', (-1, 213))]\n",
       "outputs: \n",
       "  [Tensor('float64', (-1,))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = infer_signature(X, y)\n",
    "signature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6422b80",
   "metadata": {},
   "source": [
    "##### Check that folder `./credithome_model` is deleted before lauching save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1374de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOut (mlflow.pyfunc.PythonModel):\n",
    "     def __init__(self, model):\n",
    "          self.model = model\n",
    "     def predict (self, context, model_input):\n",
    "          # here we can update the input\n",
    "          # e.g model_input.columns= map(str.lower,model_input.columns)\n",
    "          return self.model.predict_proba(model_input)[:,1]\n",
    "\n",
    "mlflow.pyfunc.save_model(python_model=ModelOut(model=pipe,),\n",
    "                         path='credithome_model',\n",
    "                         signature=signature,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c5718",
   "metadata": {},
   "source": [
    "### 4.5 shell operations to launch MLflow server on the mlflow_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7259f",
   "metadata": {},
   "source": [
    "AWS SERVER (ssh) :  \n",
    "`cd environments/env_p7/projects/exercices`  \n",
    "`mlflow models serve -m mlflow_model -h 0.0.0.0 --env-manager local`\n",
    "> parameters :  \n",
    "> `-h 0.0.0.0` to authorize http requests from anywhere on the internet (outside server)  \n",
    "> `--env-manager local` to use the default python environment and not a default conda environment\n",
    "\n",
    "LAPTOP (Anaconda powershell, environment Base) :  \n",
    "`cd '.\\OneDrive\\OpenClassrooms\\Parcours Data Scientist\\P7 Implementez Modele Scoring\\Code\\HomeCredit\\API\\'`  \n",
    "`mlflow models serve -m credithome_model -h 0.0.0.0 --env-manager local`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645f553",
   "metadata": {},
   "source": [
    "### 4.6 Test of the API (check if IP or server in model url needs to be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aa062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Test API AWS\n",
    "# model_url = 'http://ec2-18-118-129-10.us-east-2.compute.amazonaws.com:5000/invocations'\n",
    "\n",
    "# Test API LAPTOP\n",
    "model_url = 'http://localhost:5000/invocations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd87974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_test[c_features].iloc[np.random.randint(1,df_test[c_features].shape[0]),:].values\n",
    "data = df_test[c_features].iloc[0,:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 4\n",
    "tab_rep = np.zeros(max_val)\n",
    "for i in np.arange(0, max_val):\n",
    "    data = df_test[c_features].iloc[30+i,:].to_list()\n",
    "    data_json = {'data': [data]}\n",
    "    response = requests.request(method='POST',\n",
    "                                headers=headers,\n",
    "                                url=model_url,\n",
    "                                json=data_json\n",
    "                            )\n",
    "    if response.status_code != 200:\n",
    "        print(f'HTTP error: {response.status_code}')\n",
    "    else:\n",
    "        tab_rep[i] = response.json()[0]\n",
    "        print(f'{i:3} / {max_val-1:3} {response.json()}        ', end='\\r')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.DataFrame(tab_rep)\n",
    "dtf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08e83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "438838f77353e196c1617684cb98b864bf1da2ed28cf8470ba0df88c56da92f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
